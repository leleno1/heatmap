import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import io
from scipy.stats import pearsonr
import matplotlib as mpl
import matplotlib.lines as mlines
import requests
import json

# ==========================================
# ğŸ” å•†ä¸šåŒ–é…ç½® (License Config)
# ==========================================
PRO_LICENSE_KEY = "LABPLOT2025"  # ä½ å¯ä»¥éšæ—¶ä¿®æ”¹è¿™ä¸ªå¯†ç 
FREE_DPI_LIMIT = 150             # å…è´¹ç‰ˆæœ€å¤§ DPI
PRO_DPI_LIMIT = 600              # Pro ç‰ˆæœ€å¤§ DPI

# -----------------------------------------------------------------------------
# 1. é…ç½®ä¸å·¥å…·ç±» (Infrastructure)
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="LabPlot Pro: Advanced Heatmap",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åŸºç¡€ç»˜å›¾è®¾ç½®
sns.set_theme(style="white")
plt.rcParams['axes.unicode_minus'] = False

class DataProcessor:
    """å¤„ç†æ•°æ®çš„åŠ è½½ã€æ¸…æ´—ã€å˜æ¢ã€è¿‡æ»¤çš„æ ¸å¿ƒé€»è¾‘"""
    
    @staticmethod
    def load_file(file):
        try:
            if file.name.endswith('.csv'):
                return pd.read_csv(file, index_col=0)
            else:
                return pd.read_excel(file, index_col=0)
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
            return None

    @staticmethod
    def clean(df, method):
        df_num = df.apply(pd.to_numeric, errors='coerce')
        if "Keep NaN" in method: return df_num 
        if "Drop Rows" in method: return df_num.dropna()
        if "Fill with Mean" in method: return df_num.fillna(df_num.mean())
        if "Fill with Min" in method: return df_num.fillna(df_num.min().min())
        return df_num.fillna(0)

    @staticmethod
    def transform(df, method):
        if "Log2" in method: return np.log2(df.abs() + 1)
        if "Log10" in method: return np.log10(df.abs() + 1)
        return df

    @staticmethod
    def filter(df, method, top_n, selected_ids):
        if "Variance" in method:
            vars = df.var(axis=1)
            return df.loc[vars.nlargest(top_n).index], f"Top {top_n} Var"
        if "Specific IDs" in method and selected_ids:
            valid = [i for i in selected_ids if i in df.index]
            return df.loc[valid], "Manual Select"
        return df, "All Data"

    @staticmethod
    def normalize(df, mode):
        if mode == "Row (æŒ‰è¡Œ-Std)": return df.sub(df.mean(1), axis=0).div(df.std(1), axis=0)
        if mode == "Column (æŒ‰åˆ—-Std)": return df.sub(df.mean(0), axis=1).div(df.std(0), axis=1)
        if mode == "Robust Z-Score":
            med = df.median(1)
            iqr = df.quantile(0.75, 1) - df.quantile(0.25, 1)
            return df.sub(med, axis=0).div(iqr.replace(0, 1), axis=0)
        return df

    @staticmethod
    def calc_correlation(df):
        df_clean = df.dropna()
        cols = df_clean.columns
        n = len(cols)
        corr = np.zeros((n, n))
        p_vals = np.zeros((n, n))
        
        for i in range(n):
            for j in range(n):
                if i == j: 
                    corr[i, j] = 1.0
                    p_vals[i, j] = 0.0
                else:
                    r, p = pearsonr(df_clean.iloc[:, i], df_clean.iloc[:, j])
                    corr[i, j] = r
                    p_vals[i, j] = p
        
        return pd.DataFrame(corr, index=cols, columns=cols), pd.DataFrame(p_vals, index=cols, columns=cols)

class MetadataManager:
    """[å¢å¼ºç‰ˆ] ç®¡ç†æ ·æœ¬/åŸºå› çš„å…ƒæ•°æ®æ³¨é‡Šï¼Œæ”¯æŒå¤šåˆ—ä¸è‡ªåŠ¨å¯¹é½"""
    def __init__(self):
        self.meta_df = None
        self.row_colors = None
        self.col_colors = None

    def upload_ui(self, main_df):
        with st.sidebar.expander("ğŸ·ï¸ 4. åˆ†ç»„æ³¨é‡Š (Annotations)", expanded=True):
            # [Fix] æ·»åŠ  unique key é˜²æ­¢ DuplicateElementId é”™è¯¯
            file = st.file_uploader("ä¸Šä¼ åˆ†ç»„ä¿¡æ¯ (Metadata.csv)", type=["csv", "xlsx"], help="ç¬¬ä¸€åˆ—å¿…é¡»æ˜¯æ ·æœ¬IDï¼Œç”¨äºåŒ¹é…ä¸»æ•°æ®", key="metadata_uploader")
            
            if file:
                try:
                    self.meta_df = DataProcessor.load_file(file)
                    self.meta_df.index = self.meta_df.index.astype(str)
                    main_df_cols = main_df.columns.astype(str)
                    main_df_rows = main_df.index.astype(str)
                    
                    match_cols = len(main_df_cols.intersection(self.meta_df.index))
                    match_rows = len(main_df_rows.intersection(self.meta_df.index))
                    
                    target_axis = None
                    
                    if match_cols > 0 and match_cols >= match_rows:
                        target_axis = 'col'
                        st.success(f"âœ… æ£€æµ‹åˆ°åˆ—(æ ·æœ¬)æ³¨é‡Š: åŒ¹é… {match_cols}/{len(main_df.columns)}")
                    elif match_rows > 0:
                        target_axis = 'row'
                        st.success(f"âœ… æ£€æµ‹åˆ°è¡Œ(åŸºå› )æ³¨é‡Š: åŒ¹é… {match_rows}/{len(main_df.index)}")
                    else:
                        st.error("âŒ Metadata çš„ç´¢å¼•ä¸ä¸»æ•°æ®çš„è¡Œ/åˆ—åå‡ä¸åŒ¹é…ï¼")
                        return

                    selected_cols = st.multiselect(
                        "é€‰æ‹©è¦å±•ç¤ºçš„åˆ†ç»„æ¡å¸¦", 
                        self.meta_df.columns,
                        default=self.meta_df.columns[:1].tolist()
                    )
                    
                    if selected_cols:
                        color_df = pd.DataFrame(index=self.meta_df.index)
                        st.caption("ğŸ¨ åˆ†ç»„å›¾ä¾‹é¢„è§ˆ:")
                        legend_cols = st.columns(min(len(selected_cols), 4))
                        
                        for idx, col in enumerate(selected_cols):
                            series = self.meta_df[col]
                            unique_vals = series.unique()
                            pal = sns.color_palette("husl", len(unique_vals))
                            lut = dict(zip(unique_vals, pal))
                            color_df[col] = series.map(lut)
                            
                            with legend_cols[idx % 4]:
                                st.markdown(f"**{col}**")
                                for val, color in list(lut.items())[:5]:
                                    st.color_picker(f"{val}", '#%02x%02x%02x' % (int(color[0]*255), int(color[1]*255), int(color[2]*255)), disabled=True, key=f"{col}_{val}")
                        
                        if target_axis == 'col':
                            self.col_colors = color_df
                        else:
                            self.row_colors = color_df

                except Exception as e:
                    st.error(f"Metadata å¤„ç†å‡ºé”™: {e}")

class AIAssistant:
    """[ProåŠŸèƒ½] AI æ™ºèƒ½æ•°æ®è§£è¯»"""
    
    @staticmethod
    def analyze_data(df, chart_type, api_key, user_query=None):
        if not api_key:
            return "âš ï¸ è¯·è¾“å…¥ Google Gemini API Key ä»¥å¯ç”¨ AI åˆ†æã€‚"
        
        # 1. æ„å»ºæ•°æ®æ‘˜è¦ (é˜²æ­¢ Token è¶…å‡º)
        summary = ""
        if "çŸ©å½¢" in chart_type:
            # æ‰¾å‡ºå‡å€¼æœ€é«˜çš„ Top 5 å’Œæœ€ä½çš„ Top 5
            means = df.mean(axis=1).sort_values(ascending=False)
            top5 = means.head(5).index.tolist()
            bottom5 = means.tail(5).index.tolist()
            summary = f"Data Type: Expression Matrix. \nTop 5 High Expression: {top5}. \nTop 5 Low Expression: {bottom5}."
        else:
            # ç›¸å…³æ€§çŸ©é˜µï¼Œæ‰¾å‡ºå¼ºç›¸å…³ (r>0.8)
            # è¿™é‡Œçš„ df å·²ç»æ˜¯ correlation matrix
            corr = df.where(np.triu(np.ones(df.shape), k=1).astype(bool)).stack()
            strong_pos = corr[corr > 0.8].head(5).index.tolist()
            strong_neg = corr[corr < -0.8].head(5).index.tolist()
            summary = f"Data Type: Correlation Matrix. \nStrong Positive Pairs: {strong_pos}. \nStrong Negative Pairs: {strong_neg}."

        # 2. æ„å»º Prompt
        base_prompt = f"""
        Act as a senior bioinformatics scientist. Analyze the following data summary derived from a heatmap:
        {summary}
        
        Provide a concise biological insight (max 150 words) covering:
        1. Potential biological functions or pathways of the top markers (assume they are gene symbols or metabolites).
        2. A brief hypothesis about the sample condition or correlation pattern.
        3. Use professional tone.
        """
        
        # å¦‚æœç”¨æˆ·æœ‰ç‰¹å®šé—®é¢˜ï¼Œå°†å…¶åŠ å…¥ Prompt
        if user_query and user_query.strip():
            prompt = f"{base_prompt}\n\nImportant - The user has a specific question/instruction:\n{user_query}\nPlease prioritize answering the user's specific question while using the data summary as context."
        else:
            prompt = base_prompt
        
        # 3. è°ƒç”¨ API
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key={api_key}"
        headers = {'Content-Type': 'application/json'}
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        
        try:
            response = requests.post(url, headers=headers, data=json.dumps(payload))
            if response.status_code == 200:
                result = response.json()
                return result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', 'No response.')
            else:
                return f"API Error: {response.status_code} - {response.text}"
        except Exception as e:
            return f"Request Failed: {e}"

class Visualizer:
    """ç»˜å›¾å¼•æ“"""
    
    @staticmethod
    def setup_font(font_name, scale):
        sns.set_context("notebook", font_scale=scale)
        font_list = [font_name, 'SimHei', 'Arial', 'sans-serif']
        if 'Times' in font_name:
            plt.rcParams['font.family'] = 'serif'
            plt.rcParams['font.serif'] = font_list
        else:
            plt.rcParams['font.family'] = 'sans-serif'
            plt.rcParams['font.sans-serif'] = font_list

    @staticmethod
    def get_cmap(cmap_name, bad_color='lightgrey'):
        try:
            cmap = mpl.colormaps.get_cmap(cmap_name).copy()
        except:
            cmap = plt.cm.get_cmap(cmap_name).copy()
        cmap.set_bad(color=bad_color)
        return cmap

    @staticmethod
    def get_annot_matrix(df, p_df, mode):
        if mode == "None": return None
        n, m = df.shape
        annot = np.empty((n, m), dtype=object)
        for i in range(n):
            for j in range(m):
                txt = ""
                val = df.iloc[i,j]
                if pd.isna(val):
                    annot[i,j] = ""
                    continue
                if "Values" in mode: txt += f"{val:.2f}"
                if "Stars" in mode and p_df is not None:
                    p = p_df.iloc[i,j]
                    if p < 0.001: txt += "\n***" if txt else "***"
                    elif p < 0.01: txt += "\n**" if txt else "**"
                    elif p < 0.05: txt += "\n*" if txt else "*"
                annot[i, j] = txt
        return pd.DataFrame(annot, index=df.index, columns=df.columns)

    @staticmethod
    def draw_clustermap(df, meta_mgr, cmap, cbar_label, **kwargs):
        row_colors = None
        col_colors = None
        
        if meta_mgr.row_colors is not None:
            row_colors = meta_mgr.row_colors.reindex(df.index)
        
        if meta_mgr.col_colors is not None:
            col_colors = meta_mgr.col_colors.reindex(df.columns)

        g = sns.clustermap(
            df,
            row_colors=row_colors,
            col_colors=col_colors,
            cmap=cmap,
            cbar_kws={'label': cbar_label},
            **kwargs
        )
        return g

    @staticmethod
    def draw_bubble_plot(df, ax, cmap, scale_factor=100, rotation=45, vmin=None, vmax=None, triangular=False, annot_df=None, marker='o', cbar_label="Value"):
        df_plot = df.copy()
        if triangular:
            mask = np.triu(np.ones(df_plot.shape), k=1).astype(bool)
            df_plot = df_plot.mask(mask)
            if annot_df is not None: annot_df = annot_df.mask(mask)

        df_reset = df_plot.reset_index()
        index_name = df_reset.columns[0]
        
        # [ä¿®å¤] å¼ºåˆ¶æŒ‡å®š var_name å’Œ value_nameï¼Œé˜²æ­¢åŸç´¢å¼•åä½œä¸ºåˆ—åå¯¼è‡´ KeyError
        df_melt = df_reset.melt(id_vars=index_name, var_name='variable', value_name='value')
        
        df_melt = df_melt.dropna(subset=['value'])
        
        x_labels = df.columns
        y_labels = df.index
        x_map = {label: i for i, label in enumerate(x_labels)}
        y_map = {label: i for i, label in enumerate(y_labels)}
        
        df_melt['x'] = df_melt['variable'].map(x_map)
        df_melt['index_mapped'] = df_melt[index_name].map(y_map)
        
        size_values = df_melt['value'].abs()
        max_val = size_values.max() if size_values.max() != 0 else 1
        df_melt['size'] = (size_values / max_val) * scale_factor * 5
        
        scatter = ax.scatter(
            x=df_melt['x'],
            y=df_melt['index_mapped'],
            s=df_melt['size'],
            c=df_melt['value'],
            cmap=cmap,
            marker=marker,
            vmin=vmin, vmax=vmax,
            alpha=0.9, edgecolors='grey', linewidth=0.5
        )
        
        handles = []
        labels = []
        for r in [1.0, 0.5, 0.25]:
            val = max_val * r
            s = r * scale_factor * 5
            h = mlines.Line2D([], [], color='grey', marker=marker, linestyle='None',
                            markersize=np.sqrt(s), label=f'{val:.2f}')
            handles.append(h)
            labels.append(f'{val:.2f}')
        
        # [ä¿®å¤] è°ƒæ•´å›¾ä¾‹ä½ç½®åˆ° (1.35, 1) é¿å…ä¸ Colorbar å†²çª
        ax.legend(handles, labels, title="|Val|", loc='upper left', bbox_to_anchor=(1.35, 1), frameon=False)

        if annot_df is not None:
            for idx, row in df_melt.iterrows():
                r_idx = int(row['index_mapped'])
                c_idx = int(row['x'])
                try:
                    txt = annot_df.loc[y_labels[r_idx], x_labels[c_idx]]
                    if pd.notna(txt) and str(txt) != "":
                        ax.text(c_idx, r_idx, txt, ha='center', va='center', fontsize=8, color='black')
                except: pass

        ax.set_xticks(range(len(x_labels)))
        ax.set_xticklabels(x_labels, rotation=rotation, ha='right' if rotation > 0 else 'center')
        ax.set_yticks(range(len(y_labels)))
        ax.set_yticklabels(y_labels)
        ax.invert_yaxis()
        
        # [ä¿®å¤] å¼ºåˆ¶ç­‰æ¯”ä¾‹æ˜¾ç¤ºï¼Œä¿è¯æ°”æ³¡æ˜¯åœ†çš„
        ax.set_aspect('equal')
        
        for spine in ax.spines.values(): spine.set_visible(False)
        ax.grid(True, linestyle='--', alpha=0.3)
        plt.colorbar(scatter, ax=ax, label=cbar_label)
        return ax

# -----------------------------------------------------------------------------
# 3. ä¸»ç¨‹åºé€»è¾‘
# -----------------------------------------------------------------------------

def main():
    st.title("ğŸ§¬ LabPlot Pro: v3.0 Commercial")
    
    # === 0. å•†ä¸šåŒ–æ¿€æ´»åŒº (Lock) ===
    with st.sidebar.expander("ğŸ”‘ Pro ç‰ˆæ¿€æ´» (License)", expanded=True):
        license_input = st.text_input("è¾“å…¥è§£é”ç ", type="password", help="å…³æ³¨å…¬ä¼—å·'AIBio Research'å›å¤'heatmap'å…è´¹è·å–")
        is_pro = (license_input == PRO_LICENSE_KEY)
        if is_pro:
            st.success("âœ… Pro ç‰ˆå·²æ¿€æ´»ï¼æ‰€æœ‰åŠŸèƒ½è§£é”ã€‚")
        else:
            st.info("ğŸ”’ å½“å‰ä¸ºå…è´¹ç‰ˆï¼Œå…³æ³¨å…¬ä¼—å·'AIBio Research'å›å¤'heatmap'å…è´¹è·å–è§£é”ç ")
            st.caption(f"é™åˆ¶ï¼šæœ€é«˜ {FREE_DPI_LIMIT} DPIï¼Œä¸æ”¯æŒçŸ¢é‡å¯¼å‡ºï¼Œæ— æ³•ä½¿ç”¨ AIã€‚")

    # --- 1. æ•°æ®è¾“å…¥ ---
    with st.sidebar.expander("ğŸ“‚ 1. æ•°æ®è¾“å…¥ (Data)", expanded=True):
        # [Fix] æ·»åŠ  unique key é˜²æ­¢ DuplicateElementId é”™è¯¯
        file = st.file_uploader("ä¸»çŸ©é˜µ (Matrix)", type=["csv", "xlsx"], key="main_matrix_uploader")
        do_transpose = st.checkbox("è½¬ç½®ä¸»æ•°æ® (è¡Œåˆ—äº’æ¢)", value=False, help="å¦‚æœä½ çš„æ–‡ä»¶æ˜¯'è¡Œ=æ ·æœ¬'ï¼Œè¯·å‹¾é€‰æ­¤é¡¹")
        clean_method = st.selectbox("æ¸…æ´—", ["Drop Rows", "Keep NaN (ä¿ç•™ç¼ºå¤±å€¼)", "Fill 0", "Fill Mean"], 0)
        trans_method = st.selectbox("å˜æ¢", ["None", "Log2", "Log10"], 0)
        
        use_filter = st.checkbox("å¯ç”¨è¿‡æ»¤")
        filter_type, filter_n = "None", 50
        if use_filter:
            filter_type = st.radio("ç­–ç•¥", ["Variance", "Specific IDs"])
            if filter_type == "Variance": filter_n = st.number_input("Top N", 50)
            
    # --- 2. å›¾è¡¨å®šä¹‰ ---
    with st.sidebar.expander("ğŸ“Š 2. å›¾è¡¨å®šä¹‰ (Chart)", expanded=True):
        chart_type = st.radio("ç±»å‹", ["A. çŸ©å½¢çƒ­å›¾", "B. ä¸‰è§’çƒ­å›¾", "C. æ°”æ³¡çƒ­å›¾"])
        
        norm_mode = "None"
        cluster_on = False
        is_corr = False
        triangular_bubble = False
        
        if "çŸ©å½¢" in chart_type:
            cluster_on = st.checkbox("èšç±» (Clustering)", True)
            norm_mode = st.selectbox("å¤„ç†æ¨¡å¼", ["None (åŸå§‹å€¼)", "Row (æŒ‰è¡Œ-Std)", "Column (æŒ‰åˆ—-Std)", "Standard Z-Score", "Robust Z-Score", "Auto-Correlation (è®¡ç®—ç›¸å…³æ€§)"], 1)
            if "Auto-Correlation" in norm_mode: is_corr = True
            
        elif "ä¸‰è§’" in chart_type:
            st.info("è‡ªåŠ¨è®¡ç®—ç›¸å…³æ€§")
            is_corr = True
            
        elif "æ°”æ³¡" in chart_type:
            triangular_bubble = st.checkbox("ä»…æ˜¾ç¤ºä¸‹ä¸‰è§’", False)
            bubble_scale = st.slider("æ°”æ³¡å¤§å°", 10, 300, 100)
            if triangular_bubble:
                norm_mode = "Auto-Correlation"
                is_corr = True
            else:
                norm_mode = st.selectbox("æ ‡å‡†åŒ–", ["None", "Row (æŒ‰è¡Œ-Std)", "Robust Z-Score", "Auto-Correlation"], 0)
                if "Auto-Correlation" in norm_mode: is_corr = True

    # --- 3. è§†è§‰ç¾åŒ– ---
    with st.sidebar.expander("ğŸ¨ 3. è§†è§‰ (Style)", expanded=True):
        w = st.slider("å®½", 4, 20, 10)
        h = st.slider("é«˜", 4, 20, 8)
        
        st.markdown("#### é…è‰²è®¾ç½®")
        seq_cmaps = ["viridis", "YlOrRd", "Blues", "Reds", "magma"] 
        div_cmaps = ["RdBu_r", "coolwarm", "vlag", "Spectral_r"]    
        
        is_diverging = is_corr or "Row" in norm_mode or "Z-Score" in norm_mode
        if is_diverging:
            st.caption("æ¨è: åŒå‘é…è‰²")
            current_options = div_cmaps + seq_cmaps
        else:
            st.caption("æ¨è: å•å‘æ¸å˜")
            current_options = seq_cmaps + div_cmaps
            
        selected_cmap_name = st.selectbox("é…è‰²æ–¹æ¡ˆ", current_options, 0)
        
        # [æ¢å¤] è‰²å½©èŒƒå›´é”å®šåŠŸèƒ½
        use_manual_scale = st.checkbox("é”å®šè‰²å½©èŒƒå›´ (Lock Scale)", value=False, help="æ‰‹åŠ¨æŒ‡å®šæœ€å°(vmin)å’Œæœ€å¤§(vmax)å€¼ï¼Œç”¨äºç»Ÿä¸€å¤šå›¾æ ‡å‡†")
        vmin_manual, vmax_manual = None, None
        if use_manual_scale:
            col_v1, col_v2 = st.columns(2)
            with col_v1: vmin_manual = st.number_input("Min", value=-2.0, step=0.5)
            with col_v2: vmax_manual = st.number_input("Max", value=2.0, step=0.5)
        
        default_label = "Value"
        if is_corr: default_label = "Pearson r"
        elif "Row" in norm_mode or "Z-Score" in norm_mode: default_label = "Z-Score"
        elif "Log" in trans_method: default_label = "Log Expression"
        
        cbar_label_input = st.text_input("å›¾ä¾‹æ ‡ç­¾", default_label)
        annot_mode = st.selectbox("æ ‡æ³¨", ["None", "Values", "Stars", "Values + Stars"])
        font_name = st.selectbox("å­—ä½“", ["Arial", "Times New Roman", "Verdana", "SimHei"], 0)
        font_scale = st.slider("å­—å·", 0.5, 2.5, 1.2)
        
        marker_char = 'o'
        if "æ°”æ³¡" in chart_type:
            st.markdown("---")
            marker_sel = st.selectbox("æ°”æ³¡å½¢çŠ¶", ["Circle (o)", "Square (s)", "Diamond (D)", "Triangle (^)", "Hexagon (h)"], 0)
            marker_char = marker_sel.split("(")[1][0]
        
        st.markdown("---")
        custom_title = st.text_input("è‡ªå®šä¹‰æ ‡é¢˜ (Title)", "", help="ç•™ç©ºåˆ™ä¸æ˜¾ç¤ºæ ‡é¢˜")
        
    # --- 4. AI æ™ºèƒ½è§£è¯» (Locked) ---
    with st.sidebar.expander("ğŸ¤– 4. AI æ™ºèƒ½è§£è¯» (AI Insight)", expanded=False):
        if is_pro:
            gemini_key = st.text_input("Gemini API Key", type="password")
            user_query = st.text_area("è‡ªå®šä¹‰é—®é¢˜ (å¯é€‰)", placeholder="ä¾‹å¦‚ï¼šè¯·åˆ†æè¿™äº›åŸºå› ä¸ç™Œç—‡é€šè·¯çš„å…³è”...", help="ç•™ç©ºåˆ™è¿›è¡Œè‡ªåŠ¨é€šç”¨è§£è¯»")
            start_ai = st.button("ğŸ§  å¼€å§‹æ™ºèƒ½åˆ†æ")
        else:
            st.warning("ğŸ”’ AI æ™ºèƒ½åˆ†æåŠŸèƒ½ä»…é™ Pro ç‰ˆå¯ç”¨ã€‚\nè¯·åœ¨ä¾§è¾¹æ ä¸Šæ–¹è¾“å…¥è§£é”ç æ¿€æ´»ã€‚")
            start_ai = False
            gemini_key = ""
            user_query = ""

    meta_mgr = MetadataManager()
    
    # --- æ‰§è¡Œ ---
    if not file:
        st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ ä¸»æ•°æ®çŸ©é˜µ")
        return

    df = DataProcessor.load_file(file)
    if df is None: return
    
    if do_transpose:
        df = df.T
        st.caption(f"â„¹ï¸ å·²è½¬ç½®æ•°æ®ï¼Œå½“å‰ç»´åº¦: {df.shape}")

    # [Fix] åªåœ¨è¿™é‡Œè°ƒç”¨ upload_uiï¼Œç¡®ä¿åªåˆ›å»ºä¸€ä¸ª uploader
    if "çŸ©å½¢" in chart_type and cluster_on:
        meta_mgr.upload_ui(df) 
    
    df = DataProcessor.clean(df, clean_method)
    df = DataProcessor.transform(df, trans_method)
    
    sel_ids = []
    if use_filter and filter_type == "Specific IDs":
        sel_ids = st.sidebar.multiselect("é€‰æ‹©ID", df.index, df.index[:5].tolist())
    df, filter_msg = DataProcessor.filter(df, filter_type, filter_n, sel_ids)

    p_df = None
    if is_corr:
        df_plot, p_df = DataProcessor.calc_correlation(df)
    else:
        df_plot = DataProcessor.normalize(df, norm_mode)

    # --- AI Analysis Trigger ---
    if start_ai and is_pro:
        with st.status("ğŸ¤– AI æ­£åœ¨æ€è€ƒä¸­...", expanded=True) as status:
            st.write("æ­£åœ¨æå–å…³é”®ç‰¹å¾...")
            # ä¼ é€’ user_query åˆ° AI åˆ†æå‡½æ•°
            ai_result = AIAssistant.analyze_data(df_plot, chart_type, gemini_key, user_query)
            st.write("æ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
            status.update(label="âœ… åˆ†æå®Œæˆ", state="complete", expanded=True)
            st.markdown("### ğŸ§¬ AI ç”Ÿç‰©å­¦è§£è¯»æŠ¥å‘Š")
            st.info(ai_result)

    Visualizer.setup_font(font_name, font_scale)
    annot = Visualizer.get_annot_matrix(df_plot, p_df, annot_mode)
    final_cmap = Visualizer.get_cmap(selected_cmap_name, bad_color='lightgrey')
    
    st.write("---")
    with st.spinner("Rendering..."):
        try:
            fig = None
            
            # [æ–°å¢] è®¡ç®—è‰²å½©èŒƒå›´
            if use_manual_scale:
                # ç”¨æˆ·å¼ºåˆ¶é”å®š
                c_min, c_max = vmin_manual, vmax_manual
                c_center = 0 if is_diverging else None
            else:
                # æ™ºèƒ½è‡ªåŠ¨
                robust_min, robust_max = np.nanpercentile(df_plot.values, 2), np.nanpercentile(df_plot.values, 98)
                if is_diverging: # Z-score/Corr å¼ºåˆ¶å¯¹ç§°
                    lim = max(abs(robust_min), abs(robust_max))
                    c_min, c_max, c_center = -lim, lim, 0
                else: # åŸå§‹å€¼
                    c_min, c_max, c_center = robust_min, robust_max, None

            # 1. çŸ©å½¢çƒ­å›¾
            if "çŸ©å½¢" in chart_type:
                if cluster_on:
                    g = Visualizer.draw_clustermap(
                        df_plot, meta_mgr,
                        figsize=(w, h), cmap=final_cmap, annot=annot, fmt="",
                        cbar_label=cbar_label_input, 
                        method='average', metric='euclidean',
                        vmin=c_min, vmax=c_max, center=c_center, # åº”ç”¨è‰²å½©æ§åˆ¶
                        tree_kws={'linewidths': 1.5}
                    )
                    plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, ha='right')
                    fig = g.fig
                else:
                    fig, ax = plt.subplots(figsize=(w, h))
                    sns.heatmap(df_plot, ax=ax, cmap=final_cmap, annot=annot, fmt="", 
                                vmin=c_min, vmax=c_max, center=c_center, # åº”ç”¨è‰²å½©æ§åˆ¶
                                cbar_kws={'label': cbar_label_input})
                    plt.xticks(rotation=45, ha='right')
            
            # 2. ä¸‰è§’çƒ­å›¾
            elif "ä¸‰è§’" in chart_type:
                fig, ax = plt.subplots(figsize=(w, h))
                mask = np.triu(np.ones_like(df_plot))
                sns.heatmap(df_plot, mask=mask, ax=ax, cmap=final_cmap, annot=annot, fmt="", square=True,
                            vmin=c_min, vmax=c_max, center=c_center, # åº”ç”¨è‰²å½©æ§åˆ¶
                            cbar_kws={'label': cbar_label_input})
                plt.xticks(rotation=45, ha='right')
                
            # 3. æ°”æ³¡çƒ­å›¾
            elif "æ°”æ³¡" in chart_type:
                fig, ax = plt.subplots(figsize=(w, h))
                Visualizer.draw_bubble_plot(
                    df_plot, ax, final_cmap, bubble_scale, 45, 
                    annot_df=annot, triangular=triangular_bubble,
                    vmin=c_min, vmax=c_max, # åº”ç”¨è‰²å½©æ§åˆ¶
                    marker=marker_char, cbar_label=cbar_label_input
                )
            
            if fig:
                # åªåœ¨æœ‰è‡ªå®šä¹‰è¾“å…¥æ—¶æ˜¾ç¤ºæ ‡é¢˜
                if custom_title:
                    fig.suptitle(custom_title, y=1.02, fontsize=16)
                st.pyplot(fig)
                
                st.markdown("### ğŸ“¥ ä¸‹è½½å›¾è¡¨")
                c1, c2 = st.columns(2)
                
                # [Lock] ä¸‹è½½æ ¼å¼ä¸DPIçš„å•†ä¸šåŒ–é€»è¾‘
                if is_pro:
                    # Pro: å…¨æ ¼å¼ï¼Œé«˜ DPI
                    save_fmt = c1.selectbox("æ ¼å¼ (Pro Unlocked)", ["PDF", "SVG", "TIFF", "PNG", "JPG"], 0)
                    max_dpi = PRO_DPI_LIMIT
                else:
                    # Free: ä»…ä½å›¾ï¼Œä½ DPI
                    save_fmt = c1.selectbox("æ ¼å¼ (Free Limit)", ["PNG", "JPG"], 0)
                    max_dpi = FREE_DPI_LIMIT
                    
                save_dpi = c2.number_input("DPI", 72, max_dpi, min(300, max_dpi), 50)
                
                buf = io.BytesIO()
                save_fmt_lower = save_fmt.lower()
                if save_fmt_lower == "jpg": save_fmt_lower = "jpeg"
                
                fig.savefig(buf, format=save_fmt_lower, dpi=save_dpi, bbox_inches='tight', facecolor='white')
                
                # æŒ‰é’®æ–‡æ¡ˆåŒºåˆ†
                dl_label = f"ä¸‹è½½ Pro {save_fmt}" if is_pro else f"ä¸‹è½½ Free {save_fmt}"
                st.download_button(dl_label, buf.getvalue(), f"plot.{save_fmt_lower}")
                
                if not is_pro:
                    st.caption("ğŸ’¡ æƒ³è¦ PDF çŸ¢é‡å›¾å’Œ 600 DPIï¼Ÿè¯·åœ¨å·¦ä¾§æ¿€æ´» Pro ç‰ˆã€‚")

        except Exception as e:
            st.error(f"ç»˜å›¾å¤±è´¥: {e}")
            st.write("è°ƒè¯•å»ºè®®: æ£€æŸ¥æ•°æ®æ˜¯å¦åŒ…å«éæ•°å€¼å­—ç¬¦ã€‚å¦‚æœçœ‹åˆ°æ–¹æ¡†ä¹±ç ï¼Œè¯·åœ¨è§†è§‰è®¾ç½®ä¸­åˆ‡æ¢å­—ä½“ä¸º SimHeiã€‚")

if __name__ == "__main__":
    main()


